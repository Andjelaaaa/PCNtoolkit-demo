{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/predictive-clinical-neuroscience/PCNtoolkit-demo.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/PCNtoolkit-demo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T17:56:57.496449Z",
     "start_time": "2020-02-28T17:56:57.486640Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:49:43.572309Z",
     "start_time": "2020-02-27T21:49:43.566414Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats, linalg\n",
    "from sklearn import preprocessing, decomposition, linear_model, metrics \n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:47:50.679060Z",
     "start_time": "2020-02-28T18:47:50.664890Z"
    }
   },
   "outputs": [],
   "source": [
    "# set fontsizes for matplotlib plots\n",
    "baseline_fontsize = 12\n",
    "SMALL_SIZE = 8 + baseline_fontsize\n",
    "MEDIUM_SIZE = 10 + baseline_fontsize\n",
    "BIGGER_SIZE = 12 + baseline_fontsize\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:46:55.631289Z",
     "start_time": "2020-02-27T20:46:54.423706Z"
    }
   },
   "outputs": [],
   "source": [
    "all_subs = np.load('data/all_subs_regression_data.npy')\n",
    "gscores = np.load('data/g_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:46:55.650333Z",
     "start_time": "2020-02-27T20:46:55.638448Z"
    }
   },
   "outputs": [],
   "source": [
    "print(all_subs.shape)\n",
    "print(gscores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:06:31.317947Z",
     "start_time": "2020-02-28T18:06:31.286075Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate train/test splits\n",
    "np.random.seed(42)\n",
    "n_train = int(0.8 * all_subs.shape[0])\n",
    "\n",
    "train_idxs = np.random.choice(range(all_subs_T1.shape[0]), size=n_train, replace=False)\n",
    "test_idxs = np.array([x for x in range(all_subs.shape[0]) if x not in train_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T19:27:03.079155Z",
     "start_time": "2020-02-28T19:27:02.301318Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = all_subs[train_idxs, :]\n",
    "test_data = all_subs[test_idxs, :]\n",
    "\n",
    "train_phen = gscores[train_idxs]\n",
    "test_phen = gscores[test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:06:33.825306Z",
     "start_time": "2020-02-28T18:06:32.401774Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean center train/test data (using train means)\n",
    "train_mu_centered = (train_data - train_data.mean(axis=0))\n",
    "test_mu_centered = (test_data - train_data.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Regression (BBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:47:22.849443Z",
     "start_time": "2020-02-27T20:47:03.933802Z"
    }
   },
   "outputs": [],
   "source": [
    "pca_model = decomposition.PCA(n_components=75).fit(train_data)\n",
    "# from pca documentation, \"the input data is centered but not scaled for each feature before applying the SVD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:47:54.691293Z",
     "start_time": "2020-02-28T18:47:53.816603Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'First PC explains {pca_model.explained_variance_ratio_[0]*100:.2f}% of the total variance.\\nThis is an artifact of zero inflated data')\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.bar(range(1, 51), pca_model.explained_variance_ratio_[1:51])\n",
    "plt.title('Variance Explained Ratio\\nPCs 1-50', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:47:25.521344Z",
     "start_time": "2020-02-27T20:47:23.812540Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ransformed = pca_model.transform(train_data)\n",
    "test_transformed = pca_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:02:52.201826Z",
     "start_time": "2020-02-28T21:02:52.178135Z"
    }
   },
   "outputs": [],
   "source": [
    "# fast OLS using matrix math\n",
    "# we will check that this matches sklearn results later\n",
    "\n",
    "# fit ols model on dimension reduced train data\n",
    "train_features = np.hstack([np.ones((train_transformed.shape[0], 1)), \n",
    "                            train_transformed])\n",
    "train_features_inv = linalg.pinv2(train_features)\n",
    "train_betas = np.dot(train_features_inv, train_phen)\n",
    "train_pred_phen = np.dot(train_features, train_betas)\n",
    "\n",
    "# fit ols model on dimension reduced test data\n",
    "test_features = np.hstack([np.ones((test_transformed.shape[0], 1)), \n",
    "                           test_transformed])\n",
    "test_pred_phen = np.dot(test_features, train_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:02:52.511013Z",
     "start_time": "2020-02-28T21:02:52.496799Z"
    }
   },
   "outputs": [],
   "source": [
    "# OLS using sklearn\n",
    "\n",
    "lr_model = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "lr_model.fit(train_transformed, train_phen)\n",
    "train_pred_phen_lr_model = lr_model.predict(train_transformed)\n",
    "test_pred_phen_lr_model = lr_model.predict(test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:02:53.178960Z",
     "start_time": "2020-02-28T21:02:53.170282Z"
    }
   },
   "outputs": [],
   "source": [
    "# ensure matrix math predictions and sklearn predictions are accurate to 5 decimals\n",
    "assert np.allclose(np.round(train_pred_phen - train_pred_phen_lr_model, 5), 0), 'Failed'\n",
    "assert np.allclose(np.round(test_pred_phen - test_pred_phen_lr_model, 5), 0), 'Failed'\n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:03:07.671439Z",
     "start_time": "2020-02-28T21:03:07.658887Z"
    }
   },
   "outputs": [],
   "source": [
    "train_r2 = metrics.r2_score(train_phen, train_pred_phen_lr_model)\n",
    "train_mae = metrics.mean_absolute_error(train_phen, train_pred_phen_lr_model)\n",
    "test_mae = metrics.mean_absolute_error(test_phen, test_pred_phen_lr_model)\n",
    "train_mae = metrics.mean_squared_error(train_phen, train_pred_phen_lr_model)\n",
    "test_mae = metrics.mean_squared_error(test_phen, test_pred_phen_lr_model)\n",
    "print(f'Train R^2: {train_r2:.3f}')\n",
    "print(f'Train MAE: {train_mae:.3f}')\n",
    "print(f'Test MAE: {test_mae:.3f}')\n",
    "print(f'Train MSE: {train_mae:.3f}')\n",
    "print(f'Test MSE: {test_mae:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBS Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:47:30.836578Z",
     "start_time": "2020-02-27T20:47:30.818844Z"
    }
   },
   "outputs": [],
   "source": [
    "def bbs(X, y, n_components, n_cv_splits, pred_summary_function, verbose=False):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    \n",
    "    fold_accs_train = []\n",
    "    fold_accs_test = []\n",
    "    np.random.seed(42)\n",
    "    shuffled_idxs = np.random.choice(range(X.shape[0]), size=X.shape[0], replace=False)\n",
    "    for fold_i, test_idxs in enumerate(np.array_split(shuffled_idxs, n_cv_splits)):\n",
    "        train_mask = np.ones(X.shape[0], np.bool)\n",
    "        train_mask[test_idxs] = 0\n",
    "\n",
    "        # create train/text X, y\n",
    "        train_X, test_X = X[train_mask, :], X[test_idxs, :]\n",
    "        train_y, test_y = y[train_mask], y[test_idxs]  \n",
    "\n",
    "        # mean center columns using train data only\n",
    "        train_X_mu = train_X.mean(axis=0)\n",
    "        train_X = train_X - train_X_mu\n",
    "        test_X = test_X - train_X_mu\n",
    "\n",
    "        # fit pca\n",
    "        if verbose:\n",
    "            print(f'CV Fold: {fold_i+1:<10} Fitting PCA model...')\n",
    "        pca_model = decomposition.PCA(n_components=n_components).fit(train_X)\n",
    "\n",
    "        # dimension reduce train/test data\n",
    "        train_X = pca_model.transform(train_X)\n",
    "        test_X = pca_model.transform(test_X)\n",
    "\n",
    "        # fit OLS model\n",
    "        if verbose:\n",
    "            print(f'CV Fold: {fold_i+1:<10} Fitting Linear Regression model...')\n",
    "        lr_model = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "        lr_model.fit(train_X, train_y)\n",
    "\n",
    "        train_pred = lr_model.predict(train_X)\n",
    "        test_pred = lr_model.predict(test_X)\n",
    "\n",
    "        fold_accs_train.append(pred_summary_function(train_y, train_pred))\n",
    "        fold_accs_test.append(pred_summary_function(test_y, test_pred))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'CV Fold: {fold_i+1:<10} Train Accuracy: {round(fold_accs_train[-1], 3):<10} Test Accuracy: {round(fold_accs_test[-1], 3):<10}')\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(13, 7))\n",
    "    plt.plot(range(1, len(fold_accs_train)+1), fold_accs_train, linestyle='-', marker='o', color='C0', label='Train CV Performance')\n",
    "    plt.plot(range(1, len(fold_accs_test)+1), fold_accs_test, linestyle='-', marker='o', color='C1', label='Test CV Performance')\n",
    "    plt.title(pred_summary_function.__name__, fontsize=20)\n",
    "    plt.xticks(range(1, len(fold_accs_test)+1))\n",
    "    plt.xlabel('CV Fold')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    return fold_accs_train, fold_accs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:49:39.777131Z",
     "start_time": "2020-02-28T18:47:58.929094Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_accs_train, fold_accs_test = bbs(all_subs, gscores, n_components=75, n_cv_splits=5, pred_summary_function=metrics.mean_absolute_error, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectome Predictive Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:24:31.288665Z",
     "start_time": "2020-02-27T21:23:55.467812Z"
    }
   },
   "outputs": [],
   "source": [
    "# correlation train_brain with train_phenotype\n",
    "train_pheno_corr_p = [stats.pearsonr(train_data[:, i], train_phen) for i in range(train_data.shape[1])]  # train_pheno_corr_p: (259200, )\n",
    "# there are some nan correlations if brain data is poorly cropped (ie: some columns are always 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:24:34.704689Z",
     "start_time": "2020-02-27T21:24:34.501675Z"
    }
   },
   "outputs": [],
   "source": [
    "# split into positive and negative correlations \n",
    "# and keep edges with p values below threshold\n",
    "pval_threshold = 0.01\n",
    "\n",
    "train_corrs = np.array([x[0] for x in train_pheno_corr_p])\n",
    "train_pvals = np.array([x[1] for x in train_pheno_corr_p])\n",
    "\n",
    "keep_edges_pos = (train_corrs > 0) & (train_pvals < pval_threshold)\n",
    "keep_edges_neg = (train_corrs < 0) & (train_pvals < pval_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:26:12.022732Z",
     "start_time": "2020-02-27T21:26:12.013945Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'number of positive features kept = {np.sum(keep_edges_pos)}')\n",
    "print(f'number of negative features kept = {np.sum(keep_edges_neg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:29:03.616394Z",
     "start_time": "2020-02-27T21:29:03.571004Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pos_edges_sum = train_T1[:, keep_edges_pos].sum(1)\n",
    "train_neg_edges_sum = train_T1[:, keep_edges_neg].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:30:46.258668Z",
     "start_time": "2020-02-27T21:30:46.190775Z"
    }
   },
   "outputs": [],
   "source": [
    "fit_pos = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(train_pos_edges_sum.reshape(-1, 1), train_phen)\n",
    "fit_neg = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(train_neg_edges_sum.reshape(-1, 1), train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:33:41.567137Z",
     "start_time": "2020-02-27T21:33:41.557150Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_error = metrics.mean_absolute_error(train_phen, fit_pos.predict(train_pos_edges_sum.reshape(-1, 1)))\n",
    "neg_error = metrics.mean_absolute_error(train_phen, fit_neg.predict(train_neg_edges_sum.reshape(-1, 1)))\n",
    "\n",
    "print(f'Training Error (Positive Features Model) = {pos_error:.3f}')\n",
    "print(f'Training Error (Negative Features Model) = {neg_error:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:34:05.962843Z",
     "start_time": "2020-02-27T21:34:05.952234Z"
    }
   },
   "outputs": [],
   "source": [
    "# combine positive/negative edges in one linear regression model\n",
    "fit_pos_neg = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(np.stack((train_pos_edges_sum, train_neg_edges_sum)).T, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:34:40.010030Z",
     "start_time": "2020-02-27T21:34:39.990469Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_neg_error = metrics.mean_absolute_error(train_phen, fit_pos_neg.predict(np.stack((train_pos_edges_sum, train_neg_edges_sum)).T))\n",
    "\n",
    "print(f'Training Error (Positive/Negative Features Model) = {pos_neg_error:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:36:11.826718Z",
     "start_time": "2020-02-27T21:36:11.807247Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate out of sample performance \n",
    "test_pos_edges_sum = test_data[:, keep_edges_pos].sum(1)\n",
    "test_neg_edges_sum = test_data[:, keep_edges_neg].sum(1)\n",
    "\n",
    "pos_test_error = metrics.mean_absolute_error(test_phen, fit_pos.predict(test_pos_edges_sum.reshape(-1, 1)))\n",
    "neg_test_error = metrics.mean_absolute_error(test_phen, fit_neg.predict(test_neg_edges_sum.reshape(-1, 1)))\n",
    "pos_neg_test_error = metrics.mean_absolute_error(test_phen, fit_pos_neg.predict(np.stack((test_pos_edges_sum, test_neg_edges_sum)).T))\n",
    "\n",
    "print(f'Testing Error (Positive Features Model) = {pos_test_error:.3f}')\n",
    "print(f'Testing Error (Negative Features Model) = {neg_test_error:.3f}')\n",
    "print(f'Testing Error (Positive/Negative Features Model) = {pos_neg_test_error:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPM Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:52:57.609794Z",
     "start_time": "2020-02-27T21:52:57.544269Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def cpm(X, y, p_threshold, n_cv_splits, pred_summary_function, verbose=False):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    \n",
    "    fold_accs_train = []\n",
    "    fold_accs_test = []\n",
    "    np.random.seed(42)\n",
    "    shuffled_idxs = np.random.choice(range(X.shape[0]), size=X.shape[0], replace=False)\n",
    "    for fold_i, test_idxs in enumerate(np.array_split(shuffled_idxs, n_cv_splits)):\n",
    "        train_mask = np.ones(X.shape[0], np.bool)\n",
    "        train_mask[test_idxs] = 0\n",
    "\n",
    "        # create train/text X, y\n",
    "        train_X, test_X = X[train_mask, :], X[test_idxs, :]\n",
    "        train_y, test_y = y[train_mask], y[test_idxs]  \n",
    "        \n",
    "        # create correlation matrix between train_X and train_y\n",
    "        if verbose:\n",
    "            print(f'CV Fold: {fold_i+1:<10} Computing correlations between train_X and train_y...')\n",
    "        with warnings.catch_warnings():\n",
    "            # we expect pearsonr to throw PearsonRConstantInputWarning because of contant valued columns in X\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            train_pheno_corr_p = [stats.pearsonr(train_X[:, i], train_y) for i in range(train_X.shape[1])]\n",
    "            train_corrs = np.array([x[0] for x in train_pheno_corr_p])\n",
    "            train_pvals = np.array([x[1] for x in train_pheno_corr_p])\n",
    "            # create masks for edges below p-threshold and split pos/neg correlations\n",
    "            keep_edges_pos = (train_corrs > 0) & (train_pvals < p_threshold)\n",
    "            keep_edges_neg = (train_corrs < 0) & (train_pvals < p_threshold)\n",
    "        \n",
    "        # sum X entries with significant correlations with y\n",
    "        train_pos_edges_sum = train_X[:, keep_edges_pos].sum(1)\n",
    "        train_neg_edges_sum = train_X[:, keep_edges_neg].sum(1)\n",
    "        test_pos_edges_sum = test_X[:, keep_edges_pos].sum(1)\n",
    "        test_neg_edges_sum = test_X[:, keep_edges_neg].sum(1)\n",
    "        \n",
    "        # fit linear regression models based on summed values\n",
    "        fit_pos = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(train_pos_edges_sum.reshape(-1, 1), train_y)\n",
    "        fit_neg = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(train_neg_edges_sum.reshape(-1, 1), train_y)\n",
    "        fit_pos_neg = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(np.stack((train_pos_edges_sum, train_neg_edges_sum)).T, train_y)\n",
    "        \n",
    "        # compute train errors\n",
    "        train_pos_error = pred_summary_function(train_y, fit_pos.predict(train_pos_edges_sum.reshape(-1, 1)))\n",
    "        train_neg_error = pred_summary_function(train_y, fit_neg.predict(train_neg_edges_sum.reshape(-1, 1)))\n",
    "        train_posneg_error = pred_summary_function(train_y, fit_pos_neg.predict(np.stack((train_pos_edges_sum, train_neg_edges_sum)).T))\n",
    "\n",
    "        # compute testing errors\n",
    "        test_pos_error = pred_summary_function(test_y, fit_pos.predict(test_pos_edges_sum.reshape(-1, 1)))\n",
    "        test_neg_error = pred_summary_function(test_y, fit_neg.predict(test_neg_edges_sum.reshape(-1, 1)))\n",
    "        test_posneg_error = pred_summary_function(test_y, fit_pos_neg.predict(np.stack((test_pos_edges_sum, test_neg_edges_sum)).T))\n",
    "\n",
    "        fold_accs_train.append((train_pos_error, train_neg_error, train_posneg_error))\n",
    "        fold_accs_test.append((test_pos_error, test_neg_error, test_posneg_error))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'CV Fold: {fold_i+1:<10} Train Pos-Edges Model Accuracy: {round(train_pos_error, 3):<10} Train Neg-Edges Model Accuracy: {round(train_neg_error, 3):<10} Train Pos/Neg-Edges Model Accuracy: {round(train_posneg_error, 3):<10}')\n",
    "            print(f'CV Fold: {fold_i+1:<10} Test  Pos-Edges Model Accuracy: {round(test_pos_error, 3):<10} Test  Neg-Edges Model Accuracy: {round(test_neg_error, 3):<10} Test  Pos/Neg-Edges Model Accuracy: {round(test_posneg_error, 3):<10}')\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(13, 7))\n",
    "    plt.plot(range(1, len(fold_accs_train)+1), [x[0] for x in fold_accs_train], linestyle='--', marker='o', color='C0', label='Train Pos-Edges Model')\n",
    "    plt.plot(range(1, len(fold_accs_train)+1), [x[1] for x in fold_accs_train], linestyle='--', marker='o', color='C1', label='Train Neg-Edges Model')\n",
    "    plt.plot(range(1, len(fold_accs_train)+1), [x[2] for x in fold_accs_train], linestyle='--', marker='o', color='C2', label='Train Pos/Neg-Edges Model')\n",
    "    \n",
    "    plt.plot(range(1, len(fold_accs_test)+1), [x[0] for x in fold_accs_test], linestyle='-', marker='o', color='C0', label='Test  Pos-Edges Model')\n",
    "    plt.plot(range(1, len(fold_accs_test)+1), [x[1] for x in fold_accs_test], linestyle='-', marker='o', color='C1', label='Test  Neg-Edges Model')\n",
    "    plt.plot(range(1, len(fold_accs_test)+1), [x[2] for x in fold_accs_test], linestyle='-', marker='o', color='C2', label='Test  Pos/Neg-Edges Model')\n",
    "    \n",
    "    plt.title(pred_summary_function.__name__, fontsize=20)\n",
    "    plt.xticks(range(1, len(fold_accs_test)+1))\n",
    "    plt.xlabel('CV Fold')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    return fold_accs_train, fold_accs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:52:37.940960Z",
     "start_time": "2020-02-28T18:49:39.781990Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_accs_train, fold_accs_test = cpm(all_subs, gscores, p_threshold=0.01, n_cv_splits=5, pred_summary_function=metrics.mean_absolute_error, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso (Linear Regression + L1 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:57:14.623765Z",
     "start_time": "2020-02-28T18:52:40.754297Z"
    }
   },
   "outputs": [],
   "source": [
    "# LassoCV uses coordinate descent to select hyperparameter alpha \n",
    "alpha_grid = np.array([10**a for a in np.arange(-3, 3, 0.25)])\n",
    "lassoCV_model = linear_model.LassoCV(cv=5, n_alphas=len(alpha_grid), alphas=alpha_grid, fit_intercept=True, normalize=False, random_state=42, verbose=True, n_jobs=5).fit(train_data, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:23:47.189824Z",
     "start_time": "2020-02-28T20:23:46.167663Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(lassoCV_model.alphas_, lassoCV_model.mse_path_, ':')\n",
    "plt.plot(lassoCV_model.alphas_, lassoCV_model.mse_path_.mean(axis=-1), color='k', marker='o', label='Mean MSE Across Folds', linewidth=2)\n",
    "plt.axvline(x=100, linestyle='--', c='r')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T19:03:05.522140Z",
     "start_time": "2020-02-28T19:03:00.140879Z"
    }
   },
   "outputs": [],
   "source": [
    "# based on cv results above, set alpha=100\n",
    "lasso_model = linear_model.Lasso(alpha=lassoCV_model.alpha_, fit_intercept=True, normalize=False).fit(train_data, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T19:26:16.703261Z",
     "start_time": "2020-02-28T19:26:16.247169Z"
    }
   },
   "outputs": [],
   "source": [
    "train_preds_lasso_model = lasso_model.predict(train_data)\n",
    "test_preds_lasso_model = lasso_model.predict(test_data)\n",
    "\n",
    "train_mae = metrics.mean_absolute_error(train_phen, train_preds_lasso_model)\n",
    "test_mae = metrics.mean_absolute_error(test_phen, test_preds_lasso_model)\n",
    "\n",
    "print(f'Train MAE: {train_mae:.3f}')\n",
    "print(f'Test MAE: {test_mae:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge (Linear Regression + L2 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T19:24:20.576475Z",
     "start_time": "2020-02-28T19:23:29.159220Z"
    }
   },
   "outputs": [],
   "source": [
    "# RidgeCV uses generalized cross validation to select hyperparameter alpha \n",
    "with warnings.catch_warnings():\n",
    "    # ignore matrix decomposition errors\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    ridgeCV_model = linear_model.RidgeCV(alphas=(0.1, 1.0, 10.0), fit_intercept=True, normalize=False, cv=5).fit(train_data, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:04:28.613450Z",
     "start_time": "2020-02-28T20:04:28.599216Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_alpha = ridgeCV_model.alpha_\n",
    "print(f'CV Selected Alpha = {ridge_alpha:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:04:35.576044Z",
     "start_time": "2020-02-28T20:04:29.018975Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_model = linear_model.Ridge(alpha=ridge_alpha, fit_intercept=True, normalize=False).fit(train_data, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:04:36.305177Z",
     "start_time": "2020-02-28T20:04:35.589009Z"
    }
   },
   "outputs": [],
   "source": [
    "train_preds_ridge_model = ridge_model.predict(train_data)\n",
    "test_preds_ridge_model = ridge_model.predict(test_data)\n",
    "\n",
    "train_mae = metrics.mean_absolute_error(train_phen, train_preds_ridge_model)\n",
    "test_mae = metrics.mean_absolute_error(test_phen, test_preds_ridge_model)\n",
    "\n",
    "print(f'Train MAE: {train_mae:.3f}')\n",
    "print(f'Test MAE: {test_mae:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net (Linear Regression + L1/L2 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:59:20.607271Z",
     "start_time": "2020-02-28T20:25:43.581804Z"
    }
   },
   "outputs": [],
   "source": [
    "# RidgeCV uses generalized cross validation to select hyperparameter alpha \n",
    "elasticnetCV_model = linear_model.ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], cv=5, n_alphas=len(alpha_grid), alphas=alpha_grid, random_state=42, verbose=True, n_jobs=5).fit(train_data, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:59:20.620899Z",
     "start_time": "2020-02-28T20:59:20.612966Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'CV selected alpha {elasticnetCV_model.alpha_:.3f}')\n",
    "print(f'Elastic net L1 ratio {elasticnetCV_model.l1_ratio_:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:02:22.582024Z",
     "start_time": "2020-02-28T21:02:22.050171Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(elasticnetCV_model.alphas_, elasticnetCV_model.mse_path_[1, :, :], ':')\n",
    "plt.plot(elasticnetCV_model.alphas_, elasticnetCV_model.mse_path_[1, :, :].mean(axis=-1), color='k', marker='o', label='Mean MSE Across Folds', linewidth=2)\n",
    "plt.axvline(x=200, linestyle='--', c='r')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:02:35.399337Z",
     "start_time": "2020-02-28T21:02:30.121679Z"
    }
   },
   "outputs": [],
   "source": [
    "elasticnet_model = linear_model.ElasticNet(alpha=elasticnetCV_model.alpha_, l1_ratio=elasticnetCV_model.l1_ratio_, fit_intercept=True, normalize=False, random_state=42).fit(train_data, train_phen)\n",
    "\n",
    "train_preds_en_model = elasticnet_model.predict(train_data)\n",
    "test_preds_en_model = elasticnet_model.predict(test_data)\n",
    "\n",
    "train_mae = metrics.mean_absolute_error(train_phen, train_preds_en_model)\n",
    "test_mae = metrics.mean_absolute_error(test_phen, test_preds_en_model)\n",
    "\n",
    "print(f'Train MAE: {train_mae:.3f}')\n",
    "print(f'Test MAE: {test_mae:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

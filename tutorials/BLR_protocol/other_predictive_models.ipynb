{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/predictive-clinical-neuroscience/PCNtoolkit-demo.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/PCNtoolkit-demo/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T17:56:57.496449Z",
     "start_time": "2020-02-28T17:56:57.486640Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:49:43.572309Z",
     "start_time": "2020-02-27T21:49:43.566414Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats, linalg\n",
    "from sklearn import preprocessing, decomposition, linear_model, metrics \n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:47:50.679060Z",
     "start_time": "2020-02-28T18:47:50.664890Z"
    }
   },
   "outputs": [],
   "source": [
    "# set fontsizes for matplotlib plots\n",
    "baseline_fontsize = 12\n",
    "SMALL_SIZE = 8 + baseline_fontsize\n",
    "MEDIUM_SIZE = 10 + baseline_fontsize\n",
    "BIGGER_SIZE = 12 + baseline_fontsize\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:46:55.631289Z",
     "start_time": "2020-02-27T20:46:54.423706Z"
    }
   },
   "outputs": [],
   "source": [
    "hcp_z = np.load('data/hcpya_z.npy')\n",
    "hcp_ct = np.load('data/hcpya_ct.npy')\n",
    "gscores = np.load('data/hcpya_g.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:46:55.650333Z",
     "start_time": "2020-02-27T20:46:55.638448Z"
    }
   },
   "outputs": [],
   "source": [
    "print(hcp_z.shape)\n",
    "print(hcp_ct.shape)\n",
    "print(gscores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:06:31.317947Z",
     "start_time": "2020-02-28T18:06:31.286075Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate train/test splits\n",
    "np.random.seed(42)\n",
    "n_train = int(0.8 * hcp_z.shape[0])\n",
    "\n",
    "train_idxs = np.random.choice(range(hcp_z.shape[0]), size=n_train, replace=False)\n",
    "test_idxs = np.array([x for x in range(hcp_z.shape[0]) if x not in train_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T19:27:03.079155Z",
     "start_time": "2020-02-28T19:27:02.301318Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_z = hcp_z[train_idxs, :]\n",
    "test_data_z = hcp_z[test_idxs, :]\n",
    "\n",
    "train_data_ct = hcp_ct[train_idxs, :]\n",
    "test_data_ct = hcp_ct[test_idxs, :]\n",
    "\n",
    "train_phen = gscores[train_idxs]\n",
    "test_phen = gscores[test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:06:33.825306Z",
     "start_time": "2020-02-28T18:06:32.401774Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean center train/test data (using train means)\n",
    "train_mu_centered_z = (train_data_z - train_data_z.mean(axis=0))\n",
    "test_mu_centered_z = (test_data_z - train_data_z.mean(axis=0))\n",
    "\n",
    "train_mu_centered_ct = (train_data_ct - train_data_ct.mean(axis=0))\n",
    "test_mu_centered_ct = (test_data_ct - train_data_ct.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Regression (BBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:47:22.849443Z",
     "start_time": "2020-02-27T20:47:03.933802Z"
    }
   },
   "outputs": [],
   "source": [
    "pca_model_z = decomposition.PCA(n_components=75).fit(train_data_z)\n",
    "# from pca documentation, \"the input data is centered but not scaled for each feature before applying the SVD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:47:22.849443Z",
     "start_time": "2020-02-27T20:47:03.933802Z"
    }
   },
   "outputs": [],
   "source": [
    "pca_model_ct = decomposition.PCA(n_components=75).fit(train_data_ct)\n",
    "# from pca documentation, \"the input data is centered but not scaled for each feature before applying the SVD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:47:54.691293Z",
     "start_time": "2020-02-28T18:47:53.816603Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'First PC explains {pca_model_z.explained_variance_ratio_[0]*100:.2f}% of the total variance.\\nThis is an artifact of zero inflated data')\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.bar(range(1, 51), pca_model_z.explained_variance_ratio_[1:51])\n",
    "plt.title('Deviations model Variance Explained Ratio\\nPCs 1-50', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:47:54.691293Z",
     "start_time": "2020-02-28T18:47:53.816603Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'First PC explains {pca_model_ct.explained_variance_ratio_[0]*100:.2f}% of the total variance.\\nThis is an artifact of zero inflated data')\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.bar(range(1, 51), pca_model_ct.explained_variance_ratio_[1:51])\n",
    "plt.title('Cortical Thickness model Variance Explained Ratio\\nPCs 1-50', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:47:25.521344Z",
     "start_time": "2020-02-27T20:47:23.812540Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ransformed_z = pca_model_z.transform(train_data_z)\n",
    "test_transformed_z = pca_model_z.transform(test_data_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:47:25.521344Z",
     "start_time": "2020-02-27T20:47:23.812540Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ransformed_ct = pca_model_z.transform(train_data_ct)\n",
    "test_transformed_ct = pca_model_z.transform(test_data_ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:02:52.201826Z",
     "start_time": "2020-02-28T21:02:52.178135Z"
    }
   },
   "outputs": [],
   "source": [
    "# fast OLS using matrix math\n",
    "# we will check that this matches sklearn results later\n",
    "\n",
    "# fit ols model on dimension reduced train data\n",
    "train_features_z = np.hstack([np.ones((train_transformed_z.shape[0], 1)), \n",
    "                            train_transformed_z])\n",
    "train_features_inv_z = linalg.pinv2(train_features_z)\n",
    "train_betas_z = np.dot(train_features_inv_z, train_phen_z)\n",
    "train_pred_phen_z = np.dot(train_features_z, train_betas_z)\n",
    "\n",
    "# fit ols model on dimension reduced test data\n",
    "test_features_z = np.hstack([np.ones((test_transformed_z.shape[0], 1)), \n",
    "                           test_transformed_z])\n",
    "test_pred_phen_z = np.dot(test_features_z, train_betas_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:02:52.201826Z",
     "start_time": "2020-02-28T21:02:52.178135Z"
    }
   },
   "outputs": [],
   "source": [
    "# fast OLS using matrix math\n",
    "# we will check that this matches sklearn results later\n",
    "\n",
    "# fit ols model on dimension reduced train data\n",
    "train_features_ct = np.hstack([np.ones((train_transformed_ct.shape[0], 1)), \n",
    "                            train_transformed_ct])\n",
    "train_features_inv_ct = linalg.pinv2(train_features_ct)\n",
    "train_betas_ct = np.dot(train_features_inv_ct, train_phen_ct)\n",
    "train_pred_phen_ct = np.dot(train_features_ct, train_betas_ct)\n",
    "\n",
    "# fit ols model on dimension reduced test data\n",
    "test_features_ct = np.hstack([np.ones((test_transformed_ct.shape[0], 1)), \n",
    "                           test_transformed_ct])\n",
    "test_pred_phen_ct = np.dot(test_features_ct, train_betas_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:02:52.511013Z",
     "start_time": "2020-02-28T21:02:52.496799Z"
    }
   },
   "outputs": [],
   "source": [
    "# OLS using sklearn\n",
    "\n",
    "lr_model_z = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "lr_model_z.fit(train_transformed_z, train_phen_z)\n",
    "train_pred_phen_lr_model_z = lr_model_z.predict(train_transformed_z)\n",
    "test_pred_phen_lr_model_z = lr_model_z.predict(test_transformed_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:02:52.511013Z",
     "start_time": "2020-02-28T21:02:52.496799Z"
    }
   },
   "outputs": [],
   "source": [
    "# OLS using sklearn\n",
    "\n",
    "lr_model_ct = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "lr_model_ct.fit(train_transformed_ct, train_phen_ct)\n",
    "train_pred_phen_lr_model_ct = lr_model_ct.predict(train_transformed_ct)\n",
    "test_pred_phen_lr_model_ct = lr_model_ct.predict(test_transformed_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:02:53.178960Z",
     "start_time": "2020-02-28T21:02:53.170282Z"
    }
   },
   "outputs": [],
   "source": [
    "# ensure matrix math predictions and sklearn predictions are accurate to 5 decimals\n",
    "assert np.allclose(np.round(train_pred_phen_z - train_pred_phen_lr_model_z, 5), 0), 'Failed'\n",
    "assert np.allclose(np.round(test_pred_phen_z - test_pred_phen_lr_model_z, 5), 0), 'Failed'\n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:02:53.178960Z",
     "start_time": "2020-02-28T21:02:53.170282Z"
    }
   },
   "outputs": [],
   "source": [
    "# ensure matrix math predictions and sklearn predictions are accurate to 5 decimals\n",
    "assert np.allclose(np.round(train_pred_phen_ct - train_pred_phen_lr_model_ct, 5), 0), 'Failed'\n",
    "assert np.allclose(np.round(test_pred_phen_ct - test_pred_phen_lr_model_ct, 5), 0), 'Failed'\n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:03:07.671439Z",
     "start_time": "2020-02-28T21:03:07.658887Z"
    }
   },
   "outputs": [],
   "source": [
    "train_r2_z = metrics.r2_score(train_phen_z, train_pred_phen_lr_model_z)\n",
    "train_mae_z = metrics.mean_absolute_error(train_phen_z, train_pred_phen_lr_model_z)\n",
    "test_mae_z = metrics.mean_absolute_error(test_phen_z, test_pred_phen_lr_model_z)\n",
    "train_mae_z = metrics.mean_squared_error(train_phen_z, train_pred_phen_lr_model_z)\n",
    "test_mae_z = metrics.mean_squared_error(test_phen_z, test_pred_phen_lr_model_z)\n",
    "print(f'Deviation model Train R^2: {train_r2_z:.3f}')\n",
    "print(f'Deviation model Train MAE: {train_mae_z:.3f}')\n",
    "print(f'Deviation model Test MAE: {test_mae_z:.3f}')\n",
    "print(f'Deviation model Train MSE: {train_mae_z:.3f}')\n",
    "print(f'Deviation model Test MSE: {test_mae_z:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:03:07.671439Z",
     "start_time": "2020-02-28T21:03:07.658887Z"
    }
   },
   "outputs": [],
   "source": [
    "train_r2_ct = metrics.r2_score(train_phen_ct, train_pred_phen_lr_model_ct)\n",
    "train_mae_ct = metrics.mean_absolute_error(train_phen_ct, train_pred_phen_lr_model_ct)\n",
    "test_mae_ct = metrics.mean_absolute_error(test_phen_ct, test_pred_phen_lr_model_ct)\n",
    "train_mae_ct = metrics.mean_squared_error(train_phen_ct, train_pred_phen_lr_model_ct)\n",
    "test_mae_ct = metrics.mean_squared_error(test_phen_ct, test_pred_phen_lr_model_ct)\n",
    "print(f'Cortical thickness model Train R^2: {train_r2_ct:.3f}')\n",
    "print(f'Cortical thickness model Train MAE: {train_mae_ct:.3f}')\n",
    "print(f'Cortical thickness model Test MAE: {test_mae_ct:.3f}')\n",
    "print(f'Cortical thickness model Train MSE: {train_mae_ct:.3f}')\n",
    "print(f'Cortical thickness model Test MSE: {test_mae_ct:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBS Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:47:30.836578Z",
     "start_time": "2020-02-27T20:47:30.818844Z"
    }
   },
   "outputs": [],
   "source": [
    "def bbs(X, y, n_components, n_cv_splits, pred_summary_function, verbose=False):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    \n",
    "    fold_accs_train = []\n",
    "    fold_accs_test = []\n",
    "    np.random.seed(42)\n",
    "    shuffled_idxs = np.random.choice(range(X.shape[0]), size=X.shape[0], replace=False)\n",
    "    for fold_i, test_idxs in enumerate(np.array_split(shuffled_idxs, n_cv_splits)):\n",
    "        train_mask = np.ones(X.shape[0], np.bool)\n",
    "        train_mask[test_idxs] = 0\n",
    "\n",
    "        # create train/text X, y\n",
    "        train_X, test_X = X[train_mask, :], X[test_idxs, :]\n",
    "        train_y, test_y = y[train_mask], y[test_idxs]  \n",
    "\n",
    "        # mean center columns using train data only\n",
    "        train_X_mu = train_X.mean(axis=0)\n",
    "        train_X = train_X - train_X_mu\n",
    "        test_X = test_X - train_X_mu\n",
    "\n",
    "        # fit pca\n",
    "        if verbose:\n",
    "            print(f'CV Fold: {fold_i+1:<10} Fitting PCA model...')\n",
    "        pca_model = decomposition.PCA(n_components=n_components).fit(train_X)\n",
    "\n",
    "        # dimension reduce train/test data\n",
    "        train_X = pca_model.transform(train_X)\n",
    "        test_X = pca_model.transform(test_X)\n",
    "\n",
    "        # fit OLS model\n",
    "        if verbose:\n",
    "            print(f'CV Fold: {fold_i+1:<10} Fitting Linear Regression model...')\n",
    "        lr_model = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "        lr_model.fit(train_X, train_y)\n",
    "\n",
    "        train_pred = lr_model.predict(train_X)\n",
    "        test_pred = lr_model.predict(test_X)\n",
    "\n",
    "        fold_accs_train.append(pred_summary_function(train_y, train_pred))\n",
    "        fold_accs_test.append(pred_summary_function(test_y, test_pred))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'CV Fold: {fold_i+1:<10} Train Accuracy: {round(fold_accs_train[-1], 3):<10} Test Accuracy: {round(fold_accs_test[-1], 3):<10}')\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(13, 7))\n",
    "    plt.plot(range(1, len(fold_accs_train)+1), fold_accs_train, linestyle='-', marker='o', color='C0', label='Train CV Performance')\n",
    "    plt.plot(range(1, len(fold_accs_test)+1), fold_accs_test, linestyle='-', marker='o', color='C1', label='Test CV Performance')\n",
    "    plt.title(pred_summary_function.__name__, fontsize=20)\n",
    "    plt.xticks(range(1, len(fold_accs_test)+1))\n",
    "    plt.xlabel('CV Fold')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    return fold_accs_train, fold_accs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:49:39.777131Z",
     "start_time": "2020-02-28T18:47:58.929094Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_accs_train_z, fold_accs_test_z = bbs(hcp_z, gscores, n_components=75, n_cv_splits=5, pred_summary_function=metrics.mean_absolute_error, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:49:39.777131Z",
     "start_time": "2020-02-28T18:47:58.929094Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_accs_train_ct, fold_accs_test_ct = bbs(hcp_ct, gscores, n_components=75, n_cv_splits=5, pred_summary_function=metrics.mean_absolute_error, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectome Predictive Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:24:31.288665Z",
     "start_time": "2020-02-27T21:23:55.467812Z"
    }
   },
   "outputs": [],
   "source": [
    "# correlation train_brain with train_phenotype\n",
    "train_z_pheno_corr_p = [stats.pearsonr(train_data_z[:, i], train_phen) for i in range(train_data_z.shape[1])]  # train_pheno_corr_p: (259200, )\n",
    "# there are some nan correlations if brain data is poorly cropped (ie: some columns are always 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:24:31.288665Z",
     "start_time": "2020-02-27T21:23:55.467812Z"
    }
   },
   "outputs": [],
   "source": [
    "# correlation train_brain with train_phenotype\n",
    "train_ct_pheno_corr_p = [stats.pearsonr(train_data_ct[:, i], train_phen) for i in range(train_data_ct.shape[1])]  # train_pheno_corr_p: (259200, )\n",
    "# there are some nan correlations if brain data is poorly cropped (ie: some columns are always 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:24:34.704689Z",
     "start_time": "2020-02-27T21:24:34.501675Z"
    }
   },
   "outputs": [],
   "source": [
    "# split into positive and negative correlations \n",
    "# and keep edges with p values below threshold\n",
    "pval_threshold = 0.01\n",
    "\n",
    "train_z_corrs = np.array([x[0] for x in train_z_pheno_corr_p])\n",
    "train_z_pvals = np.array([x[1] for x in train_z_pheno_corr_p])\n",
    "\n",
    "keep_edges_pos_z = (train_z_corrs > 0) & (train_z_pvals < pval_threshold)\n",
    "keep_edges_neg_z = (train_z_corrs < 0) & (train_z_pvals < pval_threshold)\n",
    "\n",
    "train_ct_corrs = np.array([x[0] for x in train_ct_pheno_corr_p])\n",
    "train_ct_pvals = np.array([x[1] for x in train_ct_pheno_corr_p])\n",
    "\n",
    "keep_edges_pos_ct = (train_ct_corrs > 0) & (train_ct_pvals < pval_threshold)\n",
    "keep_edges_neg_ct = (train_ct_corrs < 0) & (train_ct_pvals < pval_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:26:12.022732Z",
     "start_time": "2020-02-27T21:26:12.013945Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'number of positive Z features kept = {np.sum(keep_edges_pos_z)}')\n",
    "print(f'number of negative Z features kept = {np.sum(keep_edges_neg_z)}')\n",
    "print(f'number of positive CT features kept = {np.sum(keep_edges_pos_ct)}')\n",
    "print(f'number of negative CT features kept = {np.sum(keep_edges_neg_ct)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:29:03.616394Z",
     "start_time": "2020-02-27T21:29:03.571004Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pos_edges_sum_z = train_data_z[:, keep_edges_pos_z].sum(1)\n",
    "train_neg_edges_sum_z = train_data_z[:, keep_edges_neg_z].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:29:03.616394Z",
     "start_time": "2020-02-27T21:29:03.571004Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pos_edges_sum_ct = train_data_ct[:, keep_edges_pos_ct].sum(1)\n",
    "train_neg_edges_sum_ct = train_data_ct[:, keep_edges_neg_ct].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:30:46.258668Z",
     "start_time": "2020-02-27T21:30:46.190775Z"
    }
   },
   "outputs": [],
   "source": [
    "fit_pos_z = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(train_pos_edges_sum_z.reshape(-1, 1), train_phen)\n",
    "fit_neg_z = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(train_neg_edges_sum_z.reshape(-1, 1), train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:30:46.258668Z",
     "start_time": "2020-02-27T21:30:46.190775Z"
    }
   },
   "outputs": [],
   "source": [
    "fit_pos_ct = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(train_pos_edges_sum_ct.reshape(-1, 1), train_phen)\n",
    "fit_neg_ct = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(train_neg_edges_sum_ct.reshape(-1, 1), train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:33:41.567137Z",
     "start_time": "2020-02-27T21:33:41.557150Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_error_z = metrics.mean_absolute_error(train_phen, fit_pos_z.predict(train_pos_edges_sum_z.reshape(-1, 1)))\n",
    "neg_error_z = metrics.mean_absolute_error(train_phen, fit_neg_z.predict(train_neg_edges_sum_z.reshape(-1, 1)))\n",
    "pos_error_ct = metrics.mean_absolute_error(train_phen, fit_pos_ct.predict(train_pos_edges_sum_ct.reshape(-1, 1)))\n",
    "neg_error_ct = metrics.mean_absolute_error(train_phen, fit_neg_ct.predict(train_neg_edges_sum_ct.reshape(-1, 1)))\n",
    "\n",
    "print(f'Training Error (Positive Z Features Model) = {pos_error_z:.3f}')\n",
    "print(f'Training Error (Negative Z Features Model) = {neg_error_z:.3f}')\n",
    "print(f'Training Error (Positive CT Features Model) = {pos_error_ct:.3f}')\n",
    "print(f'Training Error (Negative CT Features Model) = {neg_error_ct:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:34:05.962843Z",
     "start_time": "2020-02-27T21:34:05.952234Z"
    }
   },
   "outputs": [],
   "source": [
    "# combine positive/negative edges in one linear regression model\n",
    "fit_pos_neg_z = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(np.stack((train_pos_edges_sum_z, train_neg_edges_sum_z)).T, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:34:05.962843Z",
     "start_time": "2020-02-27T21:34:05.952234Z"
    }
   },
   "outputs": [],
   "source": [
    "# combine positive/negative edges in one linear regression model\n",
    "fit_pos_neg_ct = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(np.stack((train_pos_edges_sum_ct, train_neg_edges_sum_ct)).T, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:34:40.010030Z",
     "start_time": "2020-02-27T21:34:39.990469Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_neg_error_z = metrics.mean_absolute_error(train_phen, fit_pos_neg_z.predict(np.stack((train_pos_edges_sum_z, train_neg_edges_sum_z)).T))\n",
    "pos_neg_error_ct = metrics.mean_absolute_error(train_phen, fit_pos_neg_ct.predict(np.stack((train_pos_edges_sum_ct, train_neg_edges_sum_ct)).T))\n",
    "\n",
    "print(f'Training Error (Positive/Negative Z Features Model) = {pos_neg_error_z:.3f}')\n",
    "print(f'Training Error (Positive/Negative CT Features Model) = {pos_neg_error_ct:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:36:11.826718Z",
     "start_time": "2020-02-27T21:36:11.807247Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate out of sample performance \n",
    "test_pos_edges_sum_z = test_data_z[:, keep_edges_pos_z].sum(1)\n",
    "test_neg_edges_sum_z = test_data_z[:, keep_edges_neg_z].sum(1)\n",
    "\n",
    "pos_test_error_z = metrics.mean_absolute_error(test_phen, fit_pos_z.predict(test_pos_edges_sum_z.reshape(-1, 1)))\n",
    "neg_test_error_z = metrics.mean_absolute_error(test_phen, fit_neg_z.predict(test_neg_edges_sum_z.reshape(-1, 1)))\n",
    "pos_neg_test_error_z = metrics.mean_absolute_error(test_phen, fit_pos_neg_z.predict(np.stack((test_pos_edges_sum_z, test_neg_edges_sum_z)).T))\n",
    "\n",
    "test_pos_edges_sum_ct = test_data_ct[:, keep_edges_pos_ct].sum(1)\n",
    "test_neg_edges_sum_ct = test_data_ct[:, keep_edges_neg_ct].sum(1)\n",
    "\n",
    "pos_test_error_ct = metrics.mean_absolute_error(test_phen, fit_pos_ct.predict(test_pos_edges_sum_ct.reshape(-1, 1)))\n",
    "neg_test_error_ct = metrics.mean_absolute_error(test_phen, fit_neg_ct.predict(test_neg_edges_sum_ct.reshape(-1, 1)))\n",
    "pos_neg_test_error_ct = metrics.mean_absolute_error(test_phen, fit_pos_neg_ct.predict(np.stack((test_pos_edges_sum_ct, test_neg_edges_sum_ct)).T))\n",
    "\n",
    "print(f'Testing Error (Positive Z Features Model) = {pos_test_error_z:.3f}')\n",
    "print(f'Testing Error (Negative Z Features Model) = {neg_test_error_z:.3f}')\n",
    "print(f'Testing Error (Positive/Negative Z Features Model) = {pos_neg_test_error_z:.3f}')\n",
    "print(f'Testing Error (Positive CT Features Model) = {pos_test_error_ct:.3f}')\n",
    "print(f'Testing Error (Negative CT Features Model) = {neg_test_error_ct:.3f}')\n",
    "print(f'Testing Error (Positive/Negative CT Features Model) = {pos_neg_test_error_ct:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPM Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T21:52:57.609794Z",
     "start_time": "2020-02-27T21:52:57.544269Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def cpm(X, y, p_threshold, n_cv_splits, pred_summary_function, verbose=False):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    \n",
    "    fold_accs_train = []\n",
    "    fold_accs_test = []\n",
    "    np.random.seed(42)\n",
    "    shuffled_idxs = np.random.choice(range(X.shape[0]), size=X.shape[0], replace=False)\n",
    "    for fold_i, test_idxs in enumerate(np.array_split(shuffled_idxs, n_cv_splits)):\n",
    "        train_mask = np.ones(X.shape[0], np.bool)\n",
    "        train_mask[test_idxs] = 0\n",
    "\n",
    "        # create train/text X, y\n",
    "        train_X, test_X = X[train_mask, :], X[test_idxs, :]\n",
    "        train_y, test_y = y[train_mask], y[test_idxs]  \n",
    "        \n",
    "        # create correlation matrix between train_X and train_y\n",
    "        if verbose:\n",
    "            print(f'CV Fold: {fold_i+1:<10} Computing correlations between train_X and train_y...')\n",
    "        with warnings.catch_warnings():\n",
    "            # we expect pearsonr to throw PearsonRConstantInputWarning because of contant valued columns in X\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            train_pheno_corr_p = [stats.pearsonr(train_X[:, i], train_y) for i in range(train_X.shape[1])]\n",
    "            train_corrs = np.array([x[0] for x in train_pheno_corr_p])\n",
    "            train_pvals = np.array([x[1] for x in train_pheno_corr_p])\n",
    "            # create masks for edges below p-threshold and split pos/neg correlations\n",
    "            keep_edges_pos = (train_corrs > 0) & (train_pvals < p_threshold)\n",
    "            keep_edges_neg = (train_corrs < 0) & (train_pvals < p_threshold)\n",
    "        \n",
    "        # sum X entries with significant correlations with y\n",
    "        train_pos_edges_sum = train_X[:, keep_edges_pos].sum(1)\n",
    "        train_neg_edges_sum = train_X[:, keep_edges_neg].sum(1)\n",
    "        test_pos_edges_sum = test_X[:, keep_edges_pos].sum(1)\n",
    "        test_neg_edges_sum = test_X[:, keep_edges_neg].sum(1)\n",
    "        \n",
    "        # fit linear regression models based on summed values\n",
    "        fit_pos = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(train_pos_edges_sum.reshape(-1, 1), train_y)\n",
    "        fit_neg = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(train_neg_edges_sum.reshape(-1, 1), train_y)\n",
    "        fit_pos_neg = linear_model.LinearRegression(fit_intercept=True, normalize=False).fit(np.stack((train_pos_edges_sum, train_neg_edges_sum)).T, train_y)\n",
    "        \n",
    "        # compute train errors\n",
    "        train_pos_error = pred_summary_function(train_y, fit_pos.predict(train_pos_edges_sum.reshape(-1, 1)))\n",
    "        train_neg_error = pred_summary_function(train_y, fit_neg.predict(train_neg_edges_sum.reshape(-1, 1)))\n",
    "        train_posneg_error = pred_summary_function(train_y, fit_pos_neg.predict(np.stack((train_pos_edges_sum, train_neg_edges_sum)).T))\n",
    "\n",
    "        # compute testing errors\n",
    "        test_pos_error = pred_summary_function(test_y, fit_pos.predict(test_pos_edges_sum.reshape(-1, 1)))\n",
    "        test_neg_error = pred_summary_function(test_y, fit_neg.predict(test_neg_edges_sum.reshape(-1, 1)))\n",
    "        test_posneg_error = pred_summary_function(test_y, fit_pos_neg.predict(np.stack((test_pos_edges_sum, test_neg_edges_sum)).T))\n",
    "\n",
    "        fold_accs_train.append((train_pos_error, train_neg_error, train_posneg_error))\n",
    "        fold_accs_test.append((test_pos_error, test_neg_error, test_posneg_error))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'CV Fold: {fold_i+1:<10} Train Pos-Edges Model Accuracy: {round(train_pos_error, 3):<10} Train Neg-Edges Model Accuracy: {round(train_neg_error, 3):<10} Train Pos/Neg-Edges Model Accuracy: {round(train_posneg_error, 3):<10}')\n",
    "            print(f'CV Fold: {fold_i+1:<10} Test  Pos-Edges Model Accuracy: {round(test_pos_error, 3):<10} Test  Neg-Edges Model Accuracy: {round(test_neg_error, 3):<10} Test  Pos/Neg-Edges Model Accuracy: {round(test_posneg_error, 3):<10}')\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(13, 7))\n",
    "    plt.plot(range(1, len(fold_accs_train)+1), [x[0] for x in fold_accs_train], linestyle='--', marker='o', color='C0', label='Train Pos-Edges Model')\n",
    "    plt.plot(range(1, len(fold_accs_train)+1), [x[1] for x in fold_accs_train], linestyle='--', marker='o', color='C1', label='Train Neg-Edges Model')\n",
    "    plt.plot(range(1, len(fold_accs_train)+1), [x[2] for x in fold_accs_train], linestyle='--', marker='o', color='C2', label='Train Pos/Neg-Edges Model')\n",
    "    \n",
    "    plt.plot(range(1, len(fold_accs_test)+1), [x[0] for x in fold_accs_test], linestyle='-', marker='o', color='C0', label='Test  Pos-Edges Model')\n",
    "    plt.plot(range(1, len(fold_accs_test)+1), [x[1] for x in fold_accs_test], linestyle='-', marker='o', color='C1', label='Test  Neg-Edges Model')\n",
    "    plt.plot(range(1, len(fold_accs_test)+1), [x[2] for x in fold_accs_test], linestyle='-', marker='o', color='C2', label='Test  Pos/Neg-Edges Model')\n",
    "    \n",
    "    plt.title(pred_summary_function.__name__, fontsize=20)\n",
    "    plt.xticks(range(1, len(fold_accs_test)+1))\n",
    "    plt.xlabel('CV Fold')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    return fold_accs_train, fold_accs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:52:37.940960Z",
     "start_time": "2020-02-28T18:49:39.781990Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_accs_train_z, fold_accs_test_z = cpm(hcp_z, gscores, p_threshold=0.01, n_cv_splits=5, pred_summary_function=metrics.mean_absolute_error, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:52:37.940960Z",
     "start_time": "2020-02-28T18:49:39.781990Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_accs_train_ct, fold_accs_test_ct = cpm(hcp_ct, gscores, p_threshold=0.01, n_cv_splits=5, pred_summary_function=metrics.mean_absolute_error, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso (Linear Regression + L1 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:57:14.623765Z",
     "start_time": "2020-02-28T18:52:40.754297Z"
    }
   },
   "outputs": [],
   "source": [
    "# LassoCV uses coordinate descent to select hyperparameter alpha \n",
    "alpha_grid = np.array([10**a for a in np.arange(-3, 3, 0.25)])\n",
    "lassoCV_model_z = linear_model.LassoCV(cv=5, n_alphas=len(alpha_grid), alphas=alpha_grid, fit_intercept=True, normalize=False, random_state=42, verbose=True, n_jobs=5).fit(train_data_z, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T18:57:14.623765Z",
     "start_time": "2020-02-28T18:52:40.754297Z"
    }
   },
   "outputs": [],
   "source": [
    "# LassoCV uses coordinate descent to select hyperparameter alpha \n",
    "alpha_grid = np.array([10**a for a in np.arange(-3, 3, 0.25)])\n",
    "lassoCV_model_ct = linear_model.LassoCV(cv=5, n_alphas=len(alpha_grid), alphas=alpha_grid, fit_intercept=True, normalize=False, random_state=42, verbose=True, n_jobs=5).fit(train_data_ct, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:23:47.189824Z",
     "start_time": "2020-02-28T20:23:46.167663Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(lassoCV_model_z.alphas_, lassoCV_model_z.mse_path_, ':')\n",
    "plt.plot(lassoCV_model_z.alphas_, lassoCV_model_z.mse_path_.mean(axis=-1), color='k', marker='o', label='Mean MSE Across Folds Z model', linewidth=2)\n",
    "plt.axvline(x=100, linestyle='--', c='r')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:23:47.189824Z",
     "start_time": "2020-02-28T20:23:46.167663Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(lassoCV_model_ct.alphas_, lassoCV_model_ct.mse_path_, ':')\n",
    "plt.plot(lassoCV_model_ct.alphas_, lassoCV_model_ct.mse_path_.mean(axis=-1), color='k', marker='o', label='Mean MSE Across Folds CT model', linewidth=2)\n",
    "plt.axvline(x=100, linestyle='--', c='r')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T19:03:05.522140Z",
     "start_time": "2020-02-28T19:03:00.140879Z"
    }
   },
   "outputs": [],
   "source": [
    "# based on cv results above, set alpha=100\n",
    "lasso_model_z = linear_model.Lasso(alpha=lassoCV_model_z.alpha_, fit_intercept=True, normalize=False).fit(train_data_z, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T19:03:05.522140Z",
     "start_time": "2020-02-28T19:03:00.140879Z"
    }
   },
   "outputs": [],
   "source": [
    "# based on cv results above, set alpha=100\n",
    "lasso_model_ct = linear_model.Lasso(alpha=lassoCV_model_ct.alpha_, fit_intercept=True, normalize=False).fit(train_data_ct, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T19:26:16.703261Z",
     "start_time": "2020-02-28T19:26:16.247169Z"
    }
   },
   "outputs": [],
   "source": [
    "train_preds_lasso_model_z = lasso_model_z.predict(train_data_z)\n",
    "test_preds_lasso_model_z = lasso_model_z.predict(test_data_z)\n",
    "\n",
    "train_mae_z = metrics.mean_absolute_error(train_phen, train_preds_lasso_model_z)\n",
    "test_mae_z = metrics.mean_absolute_error(test_phen, test_preds_lasso_model_z)\n",
    "\n",
    "train_preds_lasso_model_ct = lasso_model_ct.predict(train_data_ct)\n",
    "test_preds_lasso_model_ct = lasso_model_ct.predict(test_data_ct)\n",
    "\n",
    "train_mae_ct = metrics.mean_absolute_error(train_phen, train_preds_lasso_model_ct)\n",
    "test_mae_ct = metrics.mean_absolute_error(test_phen, test_preds_lasso_model_ct)\n",
    "\n",
    "print(f'Train MAE Z model: {train_mae_z:.3f}')\n",
    "print(f'Test MAE Z model: {test_mae_z:.3f}')\n",
    "print(f'Train MAE CT model: {train_mae_ct:.3f}')\n",
    "print(f'Test MAE CT model: {test_mae_ct:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge (Linear Regression + L2 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T19:24:20.576475Z",
     "start_time": "2020-02-28T19:23:29.159220Z"
    }
   },
   "outputs": [],
   "source": [
    "# RidgeCV uses generalized cross validation to select hyperparameter alpha \n",
    "with warnings.catch_warnings():\n",
    "    # ignore matrix decomposition errors\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    ridgeCV_model_z = linear_model.RidgeCV(alphas=(0.1, 1.0, 10.0), fit_intercept=True, normalize=False, cv=5).fit(train_data_z, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T19:24:20.576475Z",
     "start_time": "2020-02-28T19:23:29.159220Z"
    }
   },
   "outputs": [],
   "source": [
    "# RidgeCV uses generalized cross validation to select hyperparameter alpha \n",
    "with warnings.catch_warnings():\n",
    "    # ignore matrix decomposition errors\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    ridgeCV_model_ct = linear_model.RidgeCV(alphas=(0.1, 1.0, 10.0), fit_intercept=True, normalize=False, cv=5).fit(train_data_ct, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:04:28.613450Z",
     "start_time": "2020-02-28T20:04:28.599216Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_alpha_z = ridgeCV_model_z.alpha_\n",
    "print(f'CV Selected Alpha Z model = {ridge_alpha_z:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:04:28.613450Z",
     "start_time": "2020-02-28T20:04:28.599216Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_alpha_ct = ridgeCV_model_ct.alpha_\n",
    "print(f'CV Selected Alpha CT model = {ridge_alpha_ct:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:04:35.576044Z",
     "start_time": "2020-02-28T20:04:29.018975Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_model_z = linear_model.Ridge(alpha=ridge_alpha_z, fit_intercept=True, normalize=False).fit(train_data_z, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:04:35.576044Z",
     "start_time": "2020-02-28T20:04:29.018975Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_model_ct = linear_model.Ridge(alpha=ridge_alpha_ct, fit_intercept=True, normalize=False).fit(train_data_ct, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:04:36.305177Z",
     "start_time": "2020-02-28T20:04:35.589009Z"
    }
   },
   "outputs": [],
   "source": [
    "train_preds_ridge_model_z = ridge_model_z.predict(train_data_z)\n",
    "test_preds_ridge_model_z = ridge_model_z.predict(test_data_z)\n",
    "\n",
    "train_mae_z = metrics.mean_absolute_error(train_phen, train_preds_ridge_model_z)\n",
    "test_mae_z = metrics.mean_absolute_error(test_phen, test_preds_ridge_model_z)\n",
    "\n",
    "train_preds_ridge_model_ct = ridge_model_ct.predict(train_data_ct)\n",
    "test_preds_ridge_model_ct = ridge_model_ct.predict(test_data_ct)\n",
    "\n",
    "train_mae_ct = metrics.mean_absolute_error(train_phen, train_preds_ridge_model_ct)\n",
    "test_mae_ct = metrics.mean_absolute_error(test_phen, test_preds_ridge_model_ct)\n",
    "\n",
    "print(f'Train MAE Z model: {train_mae_z:.3f}')\n",
    "print(f'Test MAE Z model: {test_mae_z:.3f}')\n",
    "print(f'Train MAE CT model: {train_mae_ct:.3f}')\n",
    "print(f'Test MAE CT model: {test_mae_ct:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net (Linear Regression + L1/L2 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:59:20.607271Z",
     "start_time": "2020-02-28T20:25:43.581804Z"
    }
   },
   "outputs": [],
   "source": [
    "# RidgeCV uses generalized cross validation to select hyperparameter alpha \n",
    "elasticnetCV_model_z = linear_model.ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], cv=5, n_alphas=len(alpha_grid), alphas=alpha_grid, random_state=42, verbose=True, n_jobs=5).fit(train_data_z, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:59:20.607271Z",
     "start_time": "2020-02-28T20:25:43.581804Z"
    }
   },
   "outputs": [],
   "source": [
    "# RidgeCV uses generalized cross validation to select hyperparameter alpha \n",
    "elasticnetCV_model_ct = linear_model.ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], cv=5, n_alphas=len(alpha_grid), alphas=alpha_grid, random_state=42, verbose=True, n_jobs=5).fit(train_data_ct, train_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T20:59:20.620899Z",
     "start_time": "2020-02-28T20:59:20.612966Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'CV selected alpha Z model {elasticnetCV_model_z.alpha_:.3f}')\n",
    "print(f'Elastic net L1 ratio Z model {elasticnetCV_model_z.l1_ratio_:.3f}')\n",
    "print(f'CV selected alpha CT model {elasticnetCV_model_ct.alpha_:.3f}')\n",
    "print(f'Elastic net L1 ratio CT model {elasticnetCV_model_ct.l1_ratio_:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:02:22.582024Z",
     "start_time": "2020-02-28T21:02:22.050171Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(elasticnetCV_model_z.alphas_, elasticnetCV_model_z.mse_path_[1, :, :], ':')\n",
    "plt.plot(elasticnetCV_model_z.alphas_, elasticnetCV_model_z.mse_path_[1, :, :].mean(axis=-1), color='k', marker='o', label='Mean MSE Across Folds', linewidth=2)\n",
    "plt.axvline(x=200, linestyle='--', c='r')\n",
    "plt.title('Alpha vs. MSE Z model')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:02:22.582024Z",
     "start_time": "2020-02-28T21:02:22.050171Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(elasticnetCV_model_ct.alphas_, elasticnetCV_model_ct.mse_path_[1, :, :], ':')\n",
    "plt.plot(elasticnetCV_model_ct.alphas_, elasticnetCV_model_ct.mse_path_[1, :, :].mean(axis=-1), color='k', marker='o', label='Mean MSE Across Folds', linewidth=2)\n",
    "plt.axvline(x=200, linestyle='--', c='r')\n",
    "plt.title('Alpha vs. MSE CT model')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:02:35.399337Z",
     "start_time": "2020-02-28T21:02:30.121679Z"
    }
   },
   "outputs": [],
   "source": [
    "elasticnet_model_z = linear_model.ElasticNet(alpha=elasticnetCV_model_z.alpha_, l1_ratio=elasticnetCV_model_z.l1_ratio_, fit_intercept=True, normalize=False, random_state=42).fit(train_data_z, train_phen)\n",
    "\n",
    "train_preds_en_model_z = elasticnet_model_z.predict(train_data_z)\n",
    "test_preds_en_model_z = elasticnet_model_z.predict(test_data_z)\n",
    "\n",
    "train_mae_z = metrics.mean_absolute_error(train_phen, train_preds_en_model_z)\n",
    "test_mae_z = metrics.mean_absolute_error(test_phen, test_preds_en_model_z)\n",
    "\n",
    "elasticnet_model_ct = linear_model.ElasticNet(alpha=elasticnetCV_model_ct.alpha_, l1_ratio=elasticnetCV_model_ct.l1_ratio_, fit_intercept=True, normalize=False, random_state=42).fit(train_data_ct, train_phen)\n",
    "\n",
    "train_preds_en_model_ct = elasticnet_model_ct.predict(train_data_ct)\n",
    "test_preds_en_model_ct = elasticnet_model_ct.predict(test_data_ct)\n",
    "\n",
    "train_mae_ct = metrics.mean_absolute_error(train_phen, train_preds_en_model_ct)\n",
    "test_mae_ct = metrics.mean_absolute_error(test_phen, test_preds_en_model_ct)\n",
    "\n",
    "print(f'Train MAE Z model: {train_mae_z:.3f}')\n",
    "print(f'Test MAE Z model: {test_mae_z:.3f}')\n",
    "print(f'Train MAE CT model: {train_mae_ct:.3f}')\n",
    "print(f'Test MAE CT model: {test_mae_ct:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Predictive Clinical Neuroscience Toolkit](https://github.com/amarquand/PCNtoolkit) \n",
    "# Normative Modeling Tutorial Using Multi-Site Cortical Thickness Data\n",
    "# Part 2: Run the normative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created by [Saige Rutherford](https://twitter.com/being_saige) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"data/NormModelSetup.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# re-run if you did not run part 1 notebook\n",
    "! wget -nc https://raw.githubusercontent.com/saigerutherford/PCNToolkit-demo/blob/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# re-run if you did not run part 1 notebook\n",
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! wget -nc https://raw.githubusercontent.com/saigerutherford/PCNToolkit-demo/blob/main/data/covariate_files/*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! wget -nc https://raw.githubusercontent.com/saigerutherford/PCNToolkit-demo/blob/main/data/response_files/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Run normative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this path to wherever your ROI_models folder is located (where you copied all of the covariate & response text files to in Part 1)\n",
    "data_dir = '/path/to/ROI_models/folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cubic B-spline basis (used for regression)\n",
    "xmin = 16 # Xmin & Xmax are the boundaries for ages of participants in the dataset\n",
    "xmax = 90\n",
    "B = create_bspline_basis(xmin, xmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reference for why we use B-spline in our design matrix](https://www.sciencedirect.com/science/article/abs/pii/S1053811910000832?via%3Dihub)\n",
    "\n",
    "[Reference for what a B-spline is](https://cran.r-project.org/web/packages/crs/vignettes/spline_primer.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all the ROIs you want to run a normative model for\n",
    "roi_ids = ['lh_bankssts_thickness',\n",
    "       'lh_caudalanteriorcingulate_thickness']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we split the data into train and test sets, we did not reset the index. This means that the row numbers in the train/test matrices are still the same as before splitting the data. We will need the test set row numbers of which subjects belong to which site in order to evaluate per site performance metrics, so we need to reset the row numbers in the train/test split matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/covariate_files/cov_tr.txt', sep='\\t', header=None)\n",
    "X_test = pd.read_csv('data/covariate_files/cov_te.txt', sep='\\t', header=None)\n",
    "y_train = pd.read_csv('data/response_files/cov_tr.txt', sep='\\t', header=None)\n",
    "y_test = pd.read_csv('data/response_files/cov_te.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of all the subejcts in each site so that we can evaluate the test set metrics per site\n",
    "cam_idx = X_test.index[X_test['site_cam' ]== 1].to_list()\n",
    "hcp_idx = X_test.index[X_test['site_hcp'] == 1].to_list()\n",
    "ixi_idx = X_test.index[X_test['site_ixi'] == 1].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the site indices into a single list\n",
    "sites = [cam_idx, hcp_idx, ixi_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with sites names to use in evaluating per-site metrics\n",
    "site_names = ['cam', 'hcp', 'ixi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas dataframes with header names to save out the overall and per-site model evaluation metrics\n",
    "blr_metrics = pd.DataFrame(columns = ['ROI', 'MSLL', 'EV', 'SMSE', 'RMSE', 'Rho'])\n",
    "blr_site_metrics = pd.DataFrame(columns = ['ROI', 'site', 'y_mean', 'y_var', 'yhat_mean', 'yhat_var', 'MSLL', 'EV', 'SMSE', 'RMSE', 'Rho'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will loop through each ROI in the list roi_ids (that was set a few rows above)\n",
    "# and run a normative model using Bayesian Linear Regression, then evaluate the normative model in the test set\n",
    "\n",
    "for roi in roi_ids: \n",
    "    print('Running ROI:', roi)\n",
    "    roi_dir = os.path.join(data_dir, roi)\n",
    "    os.chdir(roi_dir)\n",
    "    \n",
    "    # set output dir \n",
    "    out_name = 'blr'\n",
    "    os.makedirs(os.path.join(roi_dir,out_name), exist_ok=True)\n",
    "    \n",
    "    # load train & test covariate data matrices\n",
    "    X_tr = np.loadtxt(os.path.join(roi_dir, 'cov_tr.txt'))\n",
    "    X_te = np.loadtxt(os.path.join(roi_dir, 'cov_te.txt'))\n",
    "\n",
    "    # add intercept column \n",
    "    X_tr = np.concatenate((X_tr, np.ones((X_tr.shape[0],1))), axis=1)\n",
    "    X_te = np.concatenate((X_te, np.ones((X_te.shape[0],1))), axis=1)\n",
    "    # save\n",
    "    np.savetxt(os.path.join(roi_dir, 'cov_int_tr.txt'), X_tr)\n",
    "    np.savetxt(os.path.join(roi_dir, 'cov_int_te.txt'), X_te)\n",
    "    \n",
    "    # create Bspline basis set \n",
    "    Phi = np.array([B(i) for i in X_tr[:,2]])\n",
    "    Phis = np.array([B(i) for i in X_te[:,2]])\n",
    "    X_tr = np.concatenate((X_tr, Phi), axis=1)\n",
    "    X_te = np.concatenate((X_te, Phis), axis=1)\n",
    "    # save\n",
    "    np.savetxt(os.path.join(roi_dir, 'cov_bspline_tr.txt'), X_tr)\n",
    "    np.savetxt(os.path.join(roi_dir, 'cov_bspline_te.txt'), X_te)\n",
    "    \n",
    "    # configure the covariates to use\n",
    "    cov_file_tr = os.path.join(roi_dir, 'cov_') + cov_type + '_tr.txt'\n",
    "    cov_file_te = os.path.join(roi_dir, 'cov_') + cov_type + '_te.txt'\n",
    "    \n",
    "    # load train & test response files\n",
    "    resp_file_tr = os.path.join(roi_dir, 'resp_tr.txt')\n",
    "    resp_file_te = os.path.join(roi_dir, 'resp_te.txt') \n",
    "    \n",
    "    # run a basic model\n",
    "    estimate(cov_file_tr, resp_file_tr, testresp=resp_file_te, testcov=cov_file_te, alg='blr', optimizer = 'powell', savemodel=False, standardize = False, warp=warp)\n",
    "    \n",
    "    # load training data (required for MSLL)\n",
    "    y_tr = np.loadtxt(resp_file_tr)\n",
    "    y_tr = y_tr[:, np.newaxis]\n",
    "    \n",
    "    # load test data, compute metrics on whole test set, save to pandas df \n",
    "    X_te = np.loadtxt(cov_file_te)\n",
    "    y_te = np.loadtxt(resp_file_te)\n",
    "    y_te = y_te[:, np.newaxis] \n",
    "    yhat_te = np.loadtxt(os.path.join(roi_dir, 'yhat_estimate.txt'))\n",
    "    s2_te = np.loadtxt(os.path.join(roi_dir, 'ys2_estimate.txt'))\n",
    "    yhat_te = yhat_te[:, np.newaxis]\n",
    "    s2_te = s2_te[:, np.newaxis]\n",
    "    metrics_te = evaluate(y_te, yhat_te, s2_te)\n",
    "    y_mean_te = np.array([[np.mean(y_te)]])\n",
    "    y_var_te = np.array([[np.var(y_te)]])\n",
    "    MSLL_te = compute_MSLL(y_te, yhat_te, s2_te, y_mean_te, y_var_te)\n",
    "    blr_metrics.loc[len(blr_metrics)] = [roi, MSLL_te[0],metrics_te['EXPV'][0],metrics_te['SMSE'][0],metrics_te['RMSE'][0],metrics_te['Rho'][0]]\n",
    "    \n",
    "    # compute metrics per site in test set, save to pandas df\n",
    "    for num, site in enumerate(sites):\n",
    "        yhat_te_site = yhat_te[site]\n",
    "        y_te_site = y_te[site]\n",
    "        s2_te_site = s2_te[site]\n",
    "        metrics_te_site = evaluate(y_te_site, yhat_te_site, s2_te_site)\n",
    "        y_mean_te_site = np.array([[np.mean(y_te_site)]])\n",
    "        y_var_te_site = np.array([[np.var(y_te_site)]])\n",
    "        yhat_mean_te_site = np.array([[np.mean(yhat_te_site)]])\n",
    "        yhat_var_te_site = np.array([[np.var(yhat_te_site)]])\n",
    "        MSLL_te_site = compute_MSLL(y_te_site, yhat_te_site, s2_te_site, y_mean_te_site, y_var_te_site)\n",
    "        site_name = site_names[num]\n",
    "        blr_site_metrics.loc[len(blr_site_metrics)] = [roi,site_names[num],y_mean_te_site[0],y_var_te_site[0],yhat_mean_te_site[0],yhat_var_te_site[0],MSLL_te_site[0],metrics_te_site['EXPV'][0],metrics_te_site['SMSE'][0],metrics_te_site['RMSE'][0],metrics_te_site['Rho'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/saigerutherford/Desktop/lifespan/tutorial/ROI_models\n"
     ]
    }
   ],
   "source": [
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save per site test set metrics variable to CSV file\n",
    "blr_site_metrics.to_csv('blr_site_metrics.csv', index=False, index_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save overall test set metrics to CSV file\n",
    "blr_metrics.to_csv('blr_metrics.csv', index=False, index_label=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Interpreting model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output evaluation metrics definitions: \n",
    "* yhat - predictive mean\n",
    "* ys2 - predictive variance\n",
    "* nm - normative model\n",
    "* Z - deviance scores\n",
    "* Rho - Pearson correlation between true and predicted responses\n",
    "* pRho - parametric p-value for this correlation\n",
    "* RMSE - root mean squared error between true/predicted responses\n",
    "* SMSE - standardised mean squared error\n",
    "* EV - explained variance\n",
    "* MSLL - mean square log loss\n",
    "    * (Page 23) http://www.gaussianprocess.org/gpml/chapters/RW2.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
